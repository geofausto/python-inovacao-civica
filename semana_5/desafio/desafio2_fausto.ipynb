{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Desafio 2: Licitações publicadas hoje no Diário Oficial da União"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Neste desafio você irá **acessar o Portal de Compras do Governo Federal (ComprasNET)** e raspar a **descrição** de todas as licitações que foram publicadas hoje no Diário Oficial da União.\n",
    "\n",
    "Antes de começar o desafio, [acesse o site](http://comprasnet.gov.br/ConsultaLicitacoes/ConsLicitacaoDia.asp) e se familiarize com ele. É esperado que tenha bastantes licitações sendo publicadas diariamente. É assim mesmo :)\n",
    "\n",
    "Este desafio é mais livre, assim você pode experimentar mais :)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importando as bibliotecas\n",
    "\n",
    "O fluxo de raspagem deve ser:\n",
    "\n",
    "1. Acessar a primeira página que apresenta as licitações de hoje\n",
    "2. Raspar a descrição de todas as licitações da página individualmente  \n",
    "   2.1. Raspe como se fosse um bloco de texto corrido mesmo  \n",
    "   2.2. Sem raspar nenhuma etiqueta HTML junto com o texto   \n",
    "3. Adicionar os itens da página em um `DataFrame` da `pandas` apenas com os campos `data` (dia de hoje) e `descricao` (descrição da licitação)\n",
    "4. Repetir os passos 1, 2 e 3 para cada página\n",
    "5. Salvar o `DataFrame` em JSON\n",
    "\n",
    "Realize aqui os `import` necessários para esta tarefa:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Acessando a página inicial"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extraindo os itens da página inicial"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adicionando ao DataFrame"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Replicando para todas as páginas\n",
    "\n",
    "Recomenda-se transformar a extração de conteúdo da página em uma função que pode ser chamada para cada página."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def extract_licitacoes(response):\n",
    "    \"\"\"Se desejar, preencha esta função\"\"\"\n",
    "    return licitacoes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "E continuar o fluxo de extrações, página a página."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Salvando em JSON"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "3b7093543c982e412a84dff7531008243b6c8d3640829bdc6aed9bc47156caf7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}